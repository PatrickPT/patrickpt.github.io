[{"content":"TL;DR The following learning notes try to give some intuition on how Stable Diffusion works, some mathematical intuition on Diffusion Models and an introduction to Latent Diffusion Models.\nThe following sources were extensively used during creation of this learning notes. Passages may be reutilized to create a reasonable overview of the topic. Credit goes to the authors of the following papers and posts.\nIllustrations by Jay Alammar\nSohl-Dickstein et al., 2015\nHo et al. 2020\nRombach \u0026amp; Blattmann, et al. 2022\nLilian Weng on Diffusion Models\nSergios Karagiannakos on Diffusion Models\nHugging Face on Annotated Diffusion Model\nIf you recently introduced yourself to strangers and told them about your job in AI, there is a good chance they asked you about the current hype-train around the next generation of generative AI models and related data products like Dall-E, Stable Diffusion or Midjourney.\nLatent Diffusion Models like the ones above had some significant media attention. While no one outside AI community bats an eye if Deepmind creates an algorithm, that beats the (almost ancient) and important Strassen-Algorithm by some percent in computation complexity(which is a tremendous progress), nearly everyone is excited to create made up pictures of cats doing crazy stuff through a simple interface.\nDall-E 2 created picture by author - \u0026ldquo;A cat surfing a wave in comic style during sunset\u0026rdquo;\nWhile those models already made a name for themselves by winning art competitions, are adopted by companies into their related data products(Canva.com, Shutterstock.com) and start-ups creating those products raising billions in venture capital you may ask yourself:\nWhat is all the fuzz about? What is behind the hype? What are Latent Diffusion Models? What is the math behind them? Do they impact my life? What is the best way to leverage their power? Let me briefly introduce you to Diffusion Models and Latent Diffusion Models and explain the math.\nIf you are interested in a Hands-On you can find that in my other post:\nHands on Latent Diffusion Models\nIf you want an awesome visual introduction with diagrams i strongly advise to visit the blog by Jay Alammar.\nWhat is this post about: A brand-new category of cutting-edge generative models called diffusion models generate a variety of high-resolution images. They have already received a great deal of attention as a result of OpenAI, Nvidia, and Google\u0026rsquo;s success in training massive models. We\u0026rsquo;ll take a deeper look into Denoising Diffusion Probabilistic Models (also known as DDPMs, diffusion models, score-based generative models or simply autoencoders) as researchers have been able to achieve remarkable results with them for (un)conditional image/audio/video generation. Popular examples (at the time of writing) include GLIDE and DALL-E 2 by OpenAI, Latent Diffusion by the University of Heidelberg and ImageGen by Google Brain.\nIntuition on Diffusion Models You may ask \u0026ldquo;What is the intuition behind diffusion models?\u0026rdquo; Let\u0026rsquo;s break it down with a short example to make it clear: You are a painter hired by Vatican with the task to repaint the fresco at the ceiling of sixtinian chapel.\nThe requirement is to recreate the fresco with pictures of cats. The requirement is based on the old fresco and the vatican wants to have the same scenes as currently there but witch cats. So you start remembering the fresco and start bringing up a base coat and the old fresco soon becomes a big grey noise.\nMost likely you will be overwhelmed with creating a big fresco and immediately think of structuring your work into smaller chunks. Then you may outline the structures you want to paint based on your memory on the old picture and your vision on the new one.\nMaybe you start with one object like the arm of Adam, from the creation of Adam and then focus on the hand. Gradually you add more details and finally are happy with the scene, decide to finish it and tackle the next part. Still later you may change things after you decided that it fits better with the overall fresco.\nFinally you are building a masterpiece lasting centuries until someone thinks dogs are nicer than cats(so never).\nThe same idea comes with Diffusion: Gradually add noise and create the best representation of the input vision in many small steps. Breaking up the image sampling allows the models to correct itself over those small steps iteratively and produces a good sample.\nUnfortunately nothing is cost-neutral. Like it will cost a painter like Michealangelo almost 4 years to finish the fresco in Sixtinian chapel, the iterative process makes the Models slow at sampling(At least compared to GANs).\nWhat are Diffusion Models? The idea of diffusion for generative modeling was introduced in (Sohl-Dickstein et al., 2015). However, it took until (Song et al., 2019) (at Stanford University), and then (Ho et al., 2020) (at Google Brain) who independently improved the approach. DDPM which we are focussing on originally was introduced in a paper by (Ho et al., 2020).\nAt a high level, they work by first representing the input signal as a set of latent variables, which are then transformed through a series of probabilistic transformations to produce the output signal. The transformation process is designed to smooth out the noise in the input signal and reconstruct a cleaner version of the signal.\nTransformation consist of 2 processes.\nIn a bit more detail for images, the set-up consists of 2 processes:\na fixed (or predefined) forward diffusion process \\(q\\) of our choosing, that gradually adds Gaussian noise to an image, until you end up with pure noise a learned reverse denoising diffusion process \\(p_\\theta\\), where a neural network is trained to gradually denoise an image starting from pure noise, until you end up with an actual image. Diffusion Models are basically generative models: Overview of the different types of generative models\nI want to see the math Diffusion In probability theory and statistics, diffusion processes are a class of continuous-time Markov process with almost surely continuous sample paths. E.g. Brownian motion\nWikipedia says:\nA Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.\nA continuous-time Markov chain (CTMC) is a continuous stochastic process in which, for each state, the process will change state according to an exponential random variable and then move to a different state as specified by the probabilities of a stochastic matrix\nDiffusion consists of 2 processes:\na fixed (or predefined) forward diffusion process $q$ of our choosing, that gradually adds Gaussian noise to an image, until you end up with pure noise a learned reverse denoising diffusion process $p_\\theta$, where a neural network is trained to gradually denoise an image starting from pure noise, until you end up with an actual image. The Markov chain of forward (reverse) diffusion process of generating a sample by slowly adding (removing) noise. (Image source: Ho et al. 2020) and Lilian Weng\nForward Diffusion Given a data point from a real data distribution $x_0 \\sim q(x)$ we define a forward diffusion in which we add small Gaussian noise stepwise for $T$ steps producing noisy samples $\\mathbf{x}_1, \\dots, \\mathbf{x}_T$\nStep sizes are controlled by a variance schedule $0 \u0026lt; \\beta_1 \u0026lt; \\beta_2 \u0026lt; \u0026hellip; \u0026lt; \\beta_T \u0026lt; 1$.\nIt is defined as\n$q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\beta_t \\mathbf{I})$ with $\\sqrt{1 - \\beta_t} x_{t-1}$ as decay towards origin and\n$\\beta_t \\mathbf{I}$ as the addition of small noise.\nRephrased: A normal distribution (also called Gaussian distribution) is defined by 2 parameters:\na mean $\\mu$ and a variance $\\sigma^2 \\geq 0$. Basically, each new (slightly noisier) image at time step $t$ is drawn from a conditional Gaussian distribution with\n$\\mathbf{\\mu}_t = \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}$ and $\\sigma^2_t = \\beta_t$, which we can do by sampling $\\mathbf{\\epsilon} \\sim \\mathcal{N}(0, \\mathbf{I})$ and then setting $\\mathbf{x}_t = \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1} + \\sqrt{\\beta_t} \\mathbf{\\epsilon}$.\nGiven a sufficiently large $T$ and a well behaved schedule for adding noise at each time step, you end up with what is called an isotropic Gaussian distribution at $t=T$ via a gradual process.\nIsotropic means the probability density is equal (iso) in every direction (tropic). In gaussians this can be achieved with a $\\sigma^2 I$ covariance matrix.\nOne property of the diffusion process is, that you can sample $x_t$ at any time step $t$ using reparameterization trick. Let $\\alpha_{t} = 1 - \\beta_t$ and $\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i$\n$$ \\begin{aligned} \\mathbf{x}_t \u0026amp;= \\sqrt{\\alpha_t}\\mathbf{x}_{t-1} + \\sqrt{1 - \\alpha_t}\\boldsymbol{\\epsilon}_{t-1} \u0026amp; \\text{ ;where } \\boldsymbol{\\epsilon}_{t-1}, \\boldsymbol{\\epsilon}_{t-2}, \\dots \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}) \\\\ \u0026amp;= \\sqrt{\\alpha_t}\\mathbf{x}_{t-1} + \\sqrt{1 - \\alpha_t}\\boldsymbol{\\epsilon}_{t-1} \u0026amp; \\text{ ;where } \\boldsymbol{\\epsilon}_{t-1}, \\boldsymbol{\\epsilon}_{t-2}, \\dots \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}) \\\\ \u0026amp;= \\sqrt{\\alpha_t \\alpha_{t-1}} \\mathbf{x}_{t-2} + \\sqrt{1 - \\alpha_t \\alpha_{t-1}} \\bar{\\boldsymbol{\\epsilon}}_{t-2} \u0026amp; \\text{ ;where } \\bar{\\boldsymbol{\\epsilon}}_{t-2} \\text{ merges two Gaussians.} \\\\ \u0026amp;= \\dots \\\\ \u0026amp;= \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}\\\\ q(\\mathbf{x}_t \\vert \\mathbf{x}_0) \u0026amp;= \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1 - \\bar{\\alpha}_t)\\mathbf{I}) \\end{aligned} $$\nSo the sampling of noise and creation of $x_t$ is done in one step only and can be sampled at any timestep.\nReverse Diffusion $q(x_{t-1} \\vert x_t)$ which denotes the Reverse Process is intractable since statistical estimates of it require computations involving the entire dataset and therefore we need to learn a model $p_0$ to approximate these conditional probabilities in order to run the reverse diffusion process.\nWe need to learn a model $p_0$ to approximate these conditional probabilities\nSince $q(x_{t-1} \\vert x_t)$ will also be Gaussian, for small enough $\\beta_t$, we can choose $p_0$ to be Gaussian and just parameterize the mean and variance as the Reverse Diffusion:\n$\\quad p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) = \\mathcal{N} (\\mathbf{x}_{t-1}; {\\mu}_\\theta(\\mathbf{x}_t, t), {\\Sigma}_\\theta(\\mathbf{x}_t, t)) $\nwith $\\mu_\\theta(x_{t},t)$ as the mean and $\\Sigma_\\theta (x_{t},t)$ as the variance\nconditioned on the noise level $t$ as the to be learned functions of drift and covariance of the Gaussians(by a Neural Net).\nAs the target image is already defined the problem can be described as a supervised learning problem.\nAn example of training a diffusion model for modeling a 2D swiss roll data. (Image source: Sohl-Dickstein et al., 2015)\nHence, our neural network needs to learn/represent the mean and variance. However, the DDPM authors decided to keep the variance fixed, and let the neural network only learn (represent) the mean $\\mu_\\theta$ of this conditional probability distribution.\nOptimization of the Loss Function To derive an objective function to learn the mean of the backward process, the authors observe that the combination of $q$ and $p_\\theta$ can be seen as a variational auto-encoder (VAE) (Kingma et al., 2013).\nA Diffusion Model can be trained by finding the reverse Markov transitions that maximize the likelihood of the training data. In practice, training equivalently consists of minimizing the variational upper bound on the negative log likelihood\n$- \\log p_\\theta(\\mathbf{x}_0)$.\nAfter transformation(Lilian Weng for reference), we can write the evidence lower bound (ELBO) as follows:\n$$ \\begin{aligned} - \\log p_\\theta(\\mathbf{x}_0) \u0026amp;\\leq - \\log p_\\theta(\\mathbf{x}_0)+ D_\\text{KL}(q(\\mathbf{x}_{1:T}\\vert\\mathbf{x}_0) \\vert p_\\theta(\\mathbf{x}_{1:T}\\vert\\mathbf{x}_0) ) \\end{aligned} $$\nIntuition on the optimization: For a function $f(x)$, which can\u0026rsquo;t be computed(like e.g. the above negative log-likelihood) and have also a function $g(x)$, which we can compute and fullfills the condition $g(x) \u0026lt;= f(x)$. If we then maximize $g(x)$ we can be certain that $f(x)$ will also increase.\nFor optimization we use Kullback-Leibler (KL) Divergences. The KL Divergence is a statistical distance measure of how much one probability distribution $P$ differs from a reference distribution $Q$.\nWe are interested in formulating the Loss function in terms of KL divergences because the transition distributions in our Markov chain are Gaussians, and the KL divergence between Gaussians has a closed form. For a closer look please look here\nIf we rewrite the above Loss function and apply the bayesian rule the upper term can be summarized to a joint probability and will be trainsformed to the Variational Lower Bound:\n$$ \\begin{aligned} \u0026amp;= -\\log p_\\theta(\\mathbf{x}_0) + \\mathbb{E}_{\\mathbf{x}_{1:T}\\sim q(\\mathbf{x}_{1:T} \\vert \\mathbf{x}_0)} \\Big[ \\log\\frac{q(\\mathbf{x}_{1:T}\\vert\\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{0:T}) / p_\\theta(\\mathbf{x}_0)} \\Big] \\\\ \u0026amp;= -\\log p_\\theta(\\mathbf{x}_0) + \\mathbb{E}_q \\Big[ \\log\\frac{q(\\mathbf{x}_{1:T}\\vert\\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{0:T})} + \\log p_\\theta(\\mathbf{x}_0) \\Big] \\\\ \u0026amp;= \\mathbb{E}_q \\Big[ \\log \\frac{q(\\mathbf{x}_{1:T}\\vert\\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{0:T})} \\Big] \\\\ \\text{Let }L_\\text{VLB} \u0026amp;= \\mathbb{E}_{q(\\mathbf{x}_{0:T})} \\Big[ \\log \\frac{q(\\mathbf{x}_{1:T}\\vert\\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{0:T})} \\Big] \\geq - \\mathbb{E}_{q(\\mathbf{x}_0)} \\log p_\\theta(\\mathbf{x}_0) \\end{aligned} $$\nComplete calculation can be found here together with a really nice explanation here\nThe objective can be further rewritten to be a combination of several KL-divergence and entropy terms(Detailed process in Appendix B in Sohl-Dickstein et al., 2015)\n$$ \\begin{aligned} L_\\text{VLB} \u0026amp;= \\mathbb{E}_{q(\\mathbf{x}_{0:T})} \\Big[ \\log\\frac{q(\\mathbf{x}_{1:T}\\vert\\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{0:T})} \\Big] \\\\ \u0026amp;= \\dots \\\\ \u0026amp;= \\mathbb{E}_q [\\underbrace{D_\\text{KL}(q(\\mathbf{x}_T \\vert \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_T))}_{L_T} + \\sum_{t=2}^T \\underbrace{D_\\text{KL}(q(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t, \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_{t-1} \\vert\\mathbf{x}_t))}_{L_{t-1}} \\underbrace{- \\log p_\\theta(\\mathbf{x}_0 \\vert \\mathbf{x}_1)}_{L_0} ] \\end{aligned} $$\nReshaped:\n$$ \\begin{aligned} L_\\text{VLB} \u0026amp;= L_T + L_{T-1} + \\dots + L_0 \\\\ \\text{where } L_T \u0026amp;= D_\\text{KL}(q(\\mathbf{x}_T \\vert \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_T)) \\\\ L_t \u0026amp;= D_\\text{KL}(q(\\mathbf{x}_t \\vert \\mathbf{x}_{t+1}, \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_t \\vert\\mathbf{x}_{t+1})) \\text{ for }1 \\leq t \\leq T-1 \\\\ L_0 \u0026amp;= - \\log p_\\theta(\\mathbf{x}_0 \\vert \\mathbf{x}_1) \\end{aligned} $$\nEvery KL term in $L_\\text{VLB}$ except for $L_0$ compares two Gaussian distributions and therefore they can be computed in closed form. $L_T$ is constant and can be ignored during training because $q$ has no learnable parameters and $x_T$ is a Gaussian noise. $L_t$ formulates the difference between the desired denoising steps and the approximated ones.\nIt is evident that through the ELBO, maximizing the likelihood boils down to learning the denoising steps $L_t$.\nWe would like to train $\\boldsymbol{\\mu}_\\theta$ to predict $\\tilde{\\boldsymbol{\\mu}}_t = \\frac{1}{\\sqrt{\\alpha_t}} \\Big( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_t \\Big)$. Because $\\mathbf{x}_t$ is available as input at training time, we can reparameterize the Gaussian noise term instead to make it predict $\\boldsymbol{\\epsilon}_t$ from the input $\\mathbf{x}_t$ at time step $t$:\n$$ \\begin{aligned} \\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t) \u0026amp;= \\color{red}{\\frac{1}{\\sqrt{\\alpha_t}} \\Big( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\Big)} \\\\ \\text{Thus }\\mathbf{x}_{t-1} \u0026amp;= \\mathcal{N}(\\mathbf{x}_{t-1}; \\frac{1}{\\sqrt{\\alpha_t}} \\Big( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\Big), \\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t)) \\end{aligned} $$\nThe loss term $L_t$ is parameterized to minimize the difference from $\\tilde\\mu$ :\n$$ \\begin{aligned} L_t \u0026amp;= \\mathbb{E}_{\\mathbf{x}_0, \\boldsymbol{\\epsilon}} \\Big[\\frac{1}{2 | \\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t) |^2_2} | \\color{blue}{\\tilde{\\boldsymbol{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0)} - \\color{green}{\\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t)} |^2 \\Big] \\\\ \u0026amp;= \\mathbb{E}_{\\mathbf{x}_0, \\boldsymbol{\\epsilon}} \\Big[\\frac{1}{2 |\\boldsymbol{\\Sigma}_\\theta |^2_2} | \\color{blue}{\\frac{1}{\\sqrt{\\alpha_t}} \\Big( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_t \\Big)} - \\color{green}{\\frac{1}{\\sqrt{\\alpha_t}} \\Big( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\boldsymbol{\\boldsymbol{\\epsilon}}_\\theta(\\mathbf{x}_t, t) \\Big)} |^2 \\Big] \\\\ \u0026amp;= \\mathbb{E}_{\\mathbf{x}_0, \\boldsymbol{\\epsilon}} \\Big[\\frac{ (1 - \\alpha_t)^2 }{2 \\alpha_t (1 - \\bar{\\alpha}_t) | \\boldsymbol{\\Sigma}_\\theta |^2_2} |\\boldsymbol{\\epsilon}_t - \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)|^2 \\Big] \\\\ \u0026amp;= \\mathbb{E}_{\\mathbf{x}_0, \\boldsymbol{\\epsilon}} \\Big[\\frac{ (1 - \\alpha_t)^2 }{2 \\alpha_t (1 - \\bar{\\alpha}_t) | \\boldsymbol{\\Sigma}_\\theta |^2_2} |\\boldsymbol{\\epsilon}_t - \\boldsymbol{\\epsilon}_\\theta(\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}_t, t)|^2 \\Big] \\end{aligned} $$\nThe final objective function $L_t$ then looks as follows (for a random time step $t$ given $\\mathbf{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$ ) as shown by Ho et al. (2020)\n$$ | \\mathbf{\\epsilon} - \\mathbf{\\epsilon}_\\theta(\\mathbf{x}_t, t) |^2 = | \\mathbf{\\epsilon} - \\mathbf{\\epsilon}_\\theta( \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{(1- \\bar{\\alpha}_t) } \\mathbf{\\epsilon}, t) |^2.$$\nHere, $\\mathbf{x}_0$ is the initial (real, uncorrupted) image, and we see the direct noise level $t$ sample given by the fixed forward process. $\\mathbf{\\epsilon}$ is the pure noise sampled at time step $t$, and $\\mathbf{\\epsilon}_\\theta (\\mathbf{x}_t, t)$ is our neural network. The neural network is optimized using a simple mean squared error (MSE) between the true and the predicted Gaussian noise.\nHere, $\\mathbf{x}_0$ is the initial (real, uncorrupted) image, and we see the direct noise level $t$ sample given by the fixed forward process. $\\mathbf{\\epsilon}$ is the pure noise sampled at time step $t$, and $\\mathbf{\\epsilon}_\\theta (\\mathbf{x}_t, t)$ is our neural network. The neural network is optimized using a simple mean squared error (MSE) between the true and the predicted Gaussian noise.\nThe training algorithm now looks as follows:\nIn other words:\nwe take a random sample $\\mathbf{x}_0$ from the real unknown and possibily complex data distribution $q(\\mathbf{x}_0)$ we sample a noise level $t$ uniformally between $1$ and $T$ (i.e., a random time step) we sample some noise from a Gaussian distribution and corrupt the input by this noise at level $t$ (using the nice property defined above) the neural network is trained to predict this noise based on the corrupted image $\\mathbf{x}_t$ (i.e. noise applied on $\\mathbf{x}_0$ based on known schedule $\\beta_t$ ) Neural Nets The neural network needs to take in a noised image at a particular time step and return the predicted noise. Note that the predicted noise is a tensor that has the same size/resolution as the input image. So technically, the network takes in and outputs tensors of the same shape. What type of neural network can we use for this?\nWhat is typically used here is very similar to that of an Autoencoder, which you may remember from typical \u0026ldquo;intro to deep learning\u0026rdquo; tutorials. Autoencoders have a so-called \u0026ldquo;bottleneck\u0026rdquo; layer in between the encoder and decoder. The encoder first encodes an image into a smaller hidden representation called the \u0026ldquo;bottleneck\u0026rdquo;, and the decoder then decodes that hidden representation back into an actual image. This forces the network to only keep the most important information in the bottleneck layer.\nIn terms of architecture, the DDPM authors went for a U-Net, introduced by (Ronneberger et al., 2015) (which, at the time, achieved state-of-the-art results for medical image segmentation). This network, like any autoencoder, consists of a bottleneck in the middle that makes sure the network learns only the most important information. Importantly, it introduced residual connections between the encoder and decoder, greatly improving gradient flow (inspired by ResNet in He et al., 2015).\nThe math on Latent Diffusion It is very slow to generate a sample from DDPM by following the Markov chain of the reverse diffusion process, as can be up to one or a few thousand steps. One data point from Song et al. 2020: “For example, it takes around 20 hours to sample 50k images of size 32 × 32 from a DDPM, but less than a minute to do so from a GAN on an Nvidia 2080 Ti GPU.”\nLatent diffusion model (LDM; Rombach \u0026amp; Blattmann, et al. 2022) runs the diffusion process in the latent space instead of pixel space, making training cost lower and inference speed faster. It is motivated by the observation that most bits of an image contribute to perceptual details and the semantic and conceptual composition still remains after aggressive compression. LDM loosely decomposes the perceptual compression and semantic compression with generative modeling learning by first trimming off pixel-level redundancy with autoencoder and then manipulate/generate semantic concepts with diffusion process on learned latent.\nIt is motivated by the observation that most bits of an image contribute to perceptual details and the semantic and conceptual composition still remains after aggressive compression.\nLDM loosely decomposes the perceptual compression and semantic compression with generative modeling learning by first trimming off pixel-level redundancy with autoencoder and then manipulate/generate semantic concepts with diffusion process on learned latent.\nThe perceptual compression process relies on an autoencoder model.\nAn encoder $\\mathcal{E}$ is used to compress the input image $\\mathbf{x} \\in \\mathbb{R}^{H \\times W \\times 3}$ to a smaller 2D latent vector $\\mathbf{z} = \\mathcal{E}(\\mathbf{x}) \\in \\mathbb{R}^{h \\times w \\times c}$ , where the downsampling rate $f=H/h=W/w=2^m, m \\in \\mathbb{N}$.\nThen an decoder $\\mathcal{D}$ reconstructs the images from the latent vector, $\\tilde{\\mathbf{x}} = \\mathcal{D}(\\mathbf{z})$.\nThe paper explored two types of regularization in autoencoder training to avoid arbitrarily high-variance in the latent spaces.\nKL-reg: A small KL penalty towards a standard normal distribution over the learned latent, similar to VAE. VQ-reg: Uses a vector quantization layer within the decoder, like VQVAE but the quantization layer is absorbed by the decoder. The diffusion and denoising processes happen on the latent vector $\\mathbf{z}$. The denoising model is a time-conditioned U-Net, augmented with the cross-attention mechanism to handle flexible conditioning information for image generation (e.g. class labels, semantic maps, blurred variants of an image).\nThe design is equivalent to fuse representation of different modality into the model with cross-attention mechanism.\nEach type of conditioning information is paired with a domain-specific encoder $\\tau_\\theta$ to project the conditioning input $y$ to an intermediate representation that can be mapped into cross-attention component, $\\tau_\\theta(y) \\in \\mathbb{R}^{M \\times d_\\tau}$:\n$$ \\begin{aligned} \u0026amp;\\text{Attention}(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}) = \\text{softmax}\\Big(\\frac{\\mathbf{Q}\\mathbf{K}^\\top}{\\sqrt{d}}\\Big) \\cdot \\mathbf{V} \\\\ \u0026amp;\\text{where }\\mathbf{Q} = \\mathbf{W}^{(i)}_Q \\cdot \\varphi_i(\\mathbf{z}_i),; \\mathbf{K} = \\mathbf{W}^{(i)}_K \\cdot \\tau_\\theta(y),; \\mathbf{V} = \\mathbf{W}^{(i)}_V \\cdot \\tau_\\theta(y) \\\\ \u0026amp;\\text{and } \\mathbf{W}^{(i)}_Q \\in \\mathbb{R}^{d \\times d^i_\\epsilon},; \\mathbf{W}^{(i)}_K, \\mathbf{W}^{(i)}_V \\in \\mathbb{R}^{d \\times d_\\tau},; \\varphi_i(\\mathbf{z}_i) \\in \\mathbb{R}^{N \\times d^i_\\epsilon},; \\tau_\\theta(y) \\in \\mathbb{R}^{M \\times d_\\tau} \\end{aligned} $$\nPicture from J. Rafid Siddiqui\nAnd what is the result? Ressources The Annotated Diffusion Model\nHow does Stable Diffusion work? – Latent Diffusion Models EXPLAINED [Video]\nStable Diffusion - What, Why, How? [Video]\nStable Diffusion videos from fast.ai [Video]\nIllustrations by Jay Alammar Sohl-Dickstein et al., 2015\nRombach \u0026amp; Blattmann, et al. 2022\nHo et al. 2020\nLilian Weng on Diffusion Models\nSergios Karagiannakos on Diffusion Models\nHugging Face on Annotated Diffusion Model\nAssembly AI on Diffusion\nJ. Rafid Siddiqui on Latent Diffusion\n","permalink":"https://patrickpt.github.io/posts/latent-diffusion-models/","summary":"TL;DR The following learning notes try to give some intuition on how Stable Diffusion works, some mathematical intuition on Diffusion Models and an introduction to Latent Diffusion Models.\nThe following sources were extensively used during creation of this learning notes. Passages may be reutilized to create a reasonable overview of the topic. Credit goes to the authors of the following papers and posts.\nIllustrations by Jay Alammar\nSohl-Dickstein et al., 2015","title":"Latent Diffusion Models: What is all the fuzz about?"},{"content":"Prerequitises\nTo test the models here you need to have an account with HuggingFace - for loading the checkpoint or using the endpoints. Hugging Face is a community and data science platform that provides:\nTools that enable users to build, train and deploy ML models based on open source (OS) code and technologies. A place where a broad community of data scientists, researchers, and ML engineers can come together and share ideas, get support and contribute to open source projects. Recap on Latent Diffusion Models There are mutiple sites and blog posts which explain Latent Diffusion Models including my own Latent Diffusion Models: What is all the fuzz about?\nTo keep it a bit lightweight i can recommend one which explains everything with diagrams(Because i like diagrams for learning).\nBlogpost of Jay Alammar\nI don\u0026rsquo;t understand anything You don\u0026rsquo;t have any idea what this is all about?\nYou can generate beautiful pictures with the help of AI All you need to do is create a prompt and enter it into any tool using an algorithm like stable-diffusion which renders your image then. So\nThink of a prompt Examples with prompt search and Go to Dall-E Open an account and try it out. NoCode Quickstart You are not interested in getting your hands dirty? You don\u0026rsquo;t want to code? You just want to produce some nice looking images and test your prompt skills? You are not willing to pay a certain amount to use the capabilities of OpenAI\u0026rsquo;s Dall-E?\nThen this is for you:\nPrompt Ideas and References For starters, do you have any idea what you want to create and how to best create your initial prompt?\nYes\nAwesome, but as in Google Search: When you try to find the correct search prompt you need to tune the semantics of your thoughts to get what you want: How to write stable-diffusion prompts\nOf course AI can help you with this: Prompt Tuning\nNo\nNo worries, you are not the first one to create a prompt and there are already a lot of examples out there:\nExamples with prompt search\nAtlas on examples with topics\nUse an Endpoint with Stable Diffusion There are already a few websites giving you access to endpoints for free. I recommend to use one where you still have access to the codebase of the model and some evaluation. StabilityAI, the creators of stable-diffusion, an open source latent diffusion model host their model on Huggingface and give access to an endpoint (here called spaces) to test it out:\nStable Diffusion 2.1 Demo by Stability AI\nModel Card of Stable Diffusion v2\nExample Following prompt:\n\u0026ldquo;oil painting of a cat sitting on a rainbow\u0026rdquo;\nbecomes after finetuning:\n\u0026ldquo;oil painting of a cat sitting on a rainbow grass florest, sunset, cliffside ocean scene, diffuse lighting, fantasy, intricate, elegant, highly detailed, lifelike, photorealistic, digital painting, artstation, illustration, concept art, smooth, sharp focus, art by John Collier and Albert Aublet and Krenz Cushart and Artem Demura and Alphonse Mucha\u0026rdquo;\nand creates this picture with stable-diffusion: I like cats!(Like everyone else on the internet i guess)\nEnjoy exploring!\nIf you are interested in understanding how to create a Notebook with diffusors please see the following section.\nStable Diffusion \u0026hellip;using Hugging Face\u0026rsquo;s diffusers\n*The following section focusses on inference and is based on Quickstart with diffusers and Intro on diffusers\nIf you want to get a more hands-on guide on training diffusion models, please have a look at Training with Diffusers\nSummary on Diffusion Models Diffusion models are machine learning systems that are trained to denoise random gaussian noise step by step, to get to a sample of interest, such as an image.\nThe underlying model, often a neural network, is trained to predict a way to slightly denoise the image in each step. After certain number of steps, a sample is obtained.\nThe diffusion process consists in taking random noise of the size of the desired output and pass it through the model several times. The process ends after a given number of steps, and the output image should represent a sample according to the training data distribution of the model, for instance an image of a cat.\nDuring training we show many samples of a given distribution, such as images of cat. After training, the model will be able to process random noise to generate similar cat images.\nWithout going in too much detail, the model is usually not trained to directly predict a slightly less noisy image, but rather to predict the \u0026ldquo;noise residual\u0026rdquo; which is the difference between a less noisy image and the input image (for a diffusion model called \u0026ldquo;DDPM\u0026rdquo;).\nTo do the denoising process, a specific noise scheduling algorithm is thus necessary and \u0026ldquo;wrap\u0026rdquo; the model to define how many diffusion steps are needed for inference as well as how to compute a less noisy image from the model\u0026rsquo;s output.\nSummary on diffusers Stable Diffusion is based on a particular type of diffusion model called Latent Diffusion, proposed in High-Resolution Image Synthesis with Latent Diffusion Models.\nIt is created by the researchers and engineers from CompVis, Stability AI and LAION. It\u0026rsquo;s trained on 512x512 images from a subset of the LAION-5B database. This model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts. With its 860M UNet and 123M text encoder, the model is relatively lightweight and can run on many consumer GPUs. See the model card for more information.\nHowever, most of the recent research on diffusion models, e.g. DALL-E 2 and Imagen, is unfortunately not accessible to the broader machine learning community and typically remains behind closed doors.\nHere comes Hugging Face\u0026rsquo;s library for diffusion model: diffusers with the goals to:\ngather recent diffusion models from independent repositories in a single and long-term maintained project that is built by and for the community, reproduce high impact machine learning systems such as DALLE and Imagen in a manner that is accessible for the public, and create an easy to use API that enables one to train their own models or re-use checkpoints from other repositories for inference. The core API of diffusers is divided into three components:\nPipelines: high-level classes designed to rapidly generate samples from popular trained diffusion models in a user-friendly fashion. Models: popular architectures for training new diffusion models, e.g. UNet. Schedulers: various techniques for generating images from noise during inference as well as to generate noisy images for training. How-to create an Image Install diffusers !pip install diffusers==0.11.0 !pip install transformers scipy ftfy accelerate !pip install \u0026#34;ipywidgets\u0026gt;=7,\u0026lt;8\u0026#34; !pip install safetensors Input your Hugging Face Token As mentioned earlier you need a token with huggingface to import the pretrained snapshots\nfrom huggingface_hub import notebook_login notebook_login() Pipeline StableDiffusionPipeline is an end-to-end inference pipeline that you can use to generate images from text with just a few lines of code.\nFirst, we load the pre-trained weights of all components of the model. Here we use Stable Diffusion version 2.1 (stabilityai/stable-diffusion-2-1), but there are other variants that you may want to try:\nrunwayml/stable-diffusion-v1-5 stabilityai/stable-diffusion-2-1-base stabilityai/stable-diffusion-2-1. This version can produce images with a resolution of 768x768, while the others work at 512x512. This stable-diffusion-2-1 model is fine-tuned from stable-diffusion-2 (768-v-ema.ckpt) with an additional 55k steps on the same dataset (with punsafe=0.1), and then fine-tuned for another 155k extra steps with punsafe=0.98.\nIn addition to the model id stabilityai/stable-diffusion-2-1, we\u0026rsquo;re also passing a specific torch_dtype to the from_pretrained method.\nThe weights are loaded from the half-precision branch fp16 and we need to tell diffusers to expect the weights in float16 precision by passing torch_dtype=torch.float16.\nWe can import the DDPMPipeline, which will allow you to do inference with a couple of lines of code. The from_pretrained() method allows downloading the model and its configuration from the Hugging Face Hub, a repository of over 60,000 models shared by the community.\nimport torch from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler model_id = \u0026#34;stabilityai/stable-diffusion-2-1\u0026#34; # Use the DPMSolverMultistepScheduler (DPM-Solver++) scheduler here instead pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16) pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config) The pipe shows now all components contained in your desired process.\npipe StableDiffusionPipeline { \u0026#34;_class_name\u0026#34;: \u0026#34;StableDiffusionPipeline\u0026#34;, \u0026#34;_diffusers_version\u0026#34;: \u0026#34;0.11.0\u0026#34;, \u0026#34;feature_extractor\u0026#34;: [ \u0026#34;transformers\u0026#34;, \u0026#34;CLIPImageProcessor\u0026#34; ], \u0026#34;requires_safety_checker\u0026#34;: false, \u0026#34;safety_checker\u0026#34;: [ null, null ], \u0026#34;scheduler\u0026#34;: [ \u0026#34;diffusers\u0026#34;, \u0026#34;DDIMScheduler\u0026#34; ], \u0026#34;text_encoder\u0026#34;: [ \u0026#34;transformers\u0026#34;, \u0026#34;CLIPTextModel\u0026#34; ], \u0026#34;tokenizer\u0026#34;: [ \u0026#34;transformers\u0026#34;, \u0026#34;CLIPTokenizer\u0026#34; ], \u0026#34;unet\u0026#34;: [ \u0026#34;diffusers\u0026#34;, \u0026#34;UNet2DConditionModel\u0026#34; ], \u0026#34;vae\u0026#34;: [ \u0026#34;diffusers\u0026#34;, \u0026#34;AutoencoderKL\u0026#34; ] } Model Instances of the model class are neural networks that take a noisy sample as well as a timestep as inputs to predict a less noisy output sample.\nHere a simple UNet2DConditionModel which was released with the DDPM Paper is used.\npipe.unet Similarly to what we\u0026rsquo;ve seen for the pipeline class, we can load the model configuration and weights with one line, using the from_pretrained() method. It caches the model weights locally.\nScheduler Schedulers define the noise schedule which is used to add noise to the model during training, and also define the algorithm to compute the slightly less noisy sample given the model output (here noisy_residual).\nIt is important to stress here that while models have trainable weights, schedulers are usually parameter-free (in the sense they have no trainable weights) and simply define the algorithm to compute the slightly less noisy sample.\npipe.scheduler Generate Image To generate an image, we simply run the pipeline and don\u0026rsquo;t even need to give it any input, it will generate a random initial noise sample and then iterate the diffusion process. Here we use the inital prompt from above\nThe pipeline returns as output a dictionary with a generated sample of interest.\nprompt = \u0026#34;oil painting of a cat sitting on a rainbow grass florest, sunset, cliffside ocean scene, diffuse lighting, fantasy, intricate, elegant, highly detailed, lifelike, photorealistic, digital painting, artstation, illustration, concept art, smooth, sharp focus, art by John Collier and Albert Aublet and Krenz Cushart and Artem Demura and Alphonse Mucha\u0026#34; image = pipe(prompt).images[0] # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/) image.save(f\u0026#34;rainbow_cat.png\u0026#34;) Et voila\nA good video on the topic combining intuition, code and a hands-on can be found on the Youtube Channel by Edan Meyer\nReferences Latent Diffusion Models: What is all the fuzz about?\nHugging Face\nBlogpost of Jay Alammar\nDall-E\nExamples with prompt search\nAtlas on examples with topics\nHow to write stable-diffusion prompts\nPrompt Tuning\nFurther Links What\u0026rsquo;s HuggingFace on Medium\n","permalink":"https://patrickpt.github.io/posts/hands-on-latent-diffusion-models/","summary":"Prerequitises\nTo test the models here you need to have an account with HuggingFace - for loading the checkpoint or using the endpoints. Hugging Face is a community and data science platform that provides:\nTools that enable users to build, train and deploy ML models based on open source (OS) code and technologies. A place where a broad community of data scientists, researchers, and ML engineers can come together and share ideas, get support and contribute to open source projects.","title":"Hands on with Latent Diffusion Models"},{"content":"This summary is based on another post: An introduction to ChatGPT written by ChatGPT\nWhile testing out ChatGPT for some weeks now, i found that texts created by it are often repetitive and monotonous. In this post i tried to condense the meaningful information from the other post.\n2022 was the year of generative AI. Generative AI refers to machine learning algorithms that can create new meaning from text, images, code, and other forms of content. Leading generative AI tools are: DeepMind’s Alpha Code (GoogleLab), OpenAI\u0026rsquo;s ChatGPT, GPT-3.5, DALL-E, MidJourney, Jasper, and Stable Diffusion, which are large language models and image generators.\nEspecially ChatGPT(Generative Pre-trained Transformer) by OpenAI(an artificial intelligence research laboratory), the latest in AI language models had serious media attention in the last weeks. Derek Thompson wrote in The Atlantic\u0026rsquo;s \u0026ldquo;Breakthroughs of the Year\u0026rdquo; for 2022, that ChatGPT as part of \u0026ldquo;the generative-AI eruption\u0026rdquo; that \u0026ldquo;may change our mind about how we work, how we think, and what human creativity really is\u0026rdquo;.\nChatGPT is based on GPT3 (Generative Pre-trained Transformer 3) from OpenAI, a large language model that was trained using deep learning. Large language are large language models that attempt to generate human-like text and can be used for a variety of natural language processing tasks, including language translation and question answering.\nHow does ChatGPT work? The success of ChatGPT is based on training with human feedback, the so-called reinforcement learning on human feedback. This is also one of the biggest differences to previous language models. In the latest ChatGPT version, OpenAI incentivizes the feedback process in order to get even more feedback data, and sees RLHF as fundamental to artificial intelligence that takes human needs into account and thus for the development of further AI systems.\nTo collect data for training ChatGPT, the model is exposed to a variety of conversational data, including transcripts of real-world conversations, dialogues from books and movies, and other sources of conversational text. This data is used to train the model and help it understand the structure and patterns of natural language. In addition, the training is enriched by human responses and thus tuned.\nThe reward model in ChatGPT is used to evaluate the model\u0026rsquo;s performance and provide feedback on its answers. This is done through a process known as reinforcement learning, in which the model is rewarded when it generates responses that are relevant, appropriate, and human-like, and penalized when it generates responses that are irrelevant or nonsensical. This feedback helps the model learn and improve its performance over time.\nPolicies help prevent ChatGPT from generating inappropriate or offensive responses and can ensure that the model behaves in a way that is consistent with the values and norms of the organization or the people using it. For example, a policy could dictate that ChatGPT may not generate sexist, racist, or otherwise discriminatory responses.\nWhat are the limitations and pitfalls of ChatGPT? ChatGPT is not capable of real understanding, and its answers are based on the data it was trained on and the algorithms that drive its behavior. ChatGPT is unable to really handle the complexities of human language and conversation. ChatGPT is not intelligent.\nIt is trained to generate words based on a given input without the ability to really understand the meaning behind those words. That means any answers it generates are likely to be superficial and lack depth and insight. When using it, you also notice a repetitive and monotonous language. There are already models that are able to distinguish between text generated by a GPT model and text written by a human.\nIf the model was trained on data that is biased or discriminatory, it can generate responses that are unfair or offensive but sound reasonable or logical. Therefore, it is important to carefully review and evaluate ChatGPT\u0026rsquo;s responses. Because the model definitely generates wrong answers that sound semantically correct. It is therefore important to ensure that ChatGPT is used in an ethical and responsible manner.\nWhat brings the future? The entry of AI models like ChatGPT into normal everyday work will become reality in the coming months to years. Microsoft - shareholder of OpenAI - is already thinking aloud about using the model in Bing or Office products. Despite some problems, they still have enormous potential to speed up and improve daily work.\nAnother concrete example is Github Copilot. Copilot is powered by OpenAI Codex, another model of OpenAI. Codex is a modified production version of GPT-3. The Codex model is also trained on source code and specifically aims at generating program code. The Copilot beta ended in 2022 and you can already significantly improve your code generation workflow.\nChatGPT is an impressive development in the field of artificial intelligence, and marks a media milestone, but is only a snapshot. GPT4 is the next generation of the GPT language model and will be even more powerful than GPT3. GPT-4 consists of 170 trillion parameters compared to GPT-3\u0026rsquo;s 175 billion parameters. The accuracy of the models will therefore increase further in the future and will continue to find their way into our everyday lives.\nReferences ChatGPT: Optimizing Language Models for Dialogue\nAtlantic: The rise of AI\nAI Hopes and Horrors\n","permalink":"https://patrickpt.github.io/posts/summary-chatgpt/","summary":"This summary is based on another post: An introduction to ChatGPT written by ChatGPT\nWhile testing out ChatGPT for some weeks now, i found that texts created by it are often repetitive and monotonous. In this post i tried to condense the meaningful information from the other post.\n2022 was the year of generative AI. Generative AI refers to machine learning algorithms that can create new meaning from text, images, code, and other forms of content.","title":"A short summary on ChatGPT"},{"content":"ChatGPT: Optimizing Language Models for Dialogue\nWhat to do if you have 15Min time to spare? Feed ChatGPT with prompts to write an introductory article about ChatGPT. And I promise, this is the only part which is not based on a Large Language Model. Everything else was written by ChatGPT. For better readability I replaced the prompts with simple headers.\nWhat is ChatGPT? Are you tired of boring, robotic chatbots that can’t hold a conversation or understand your needs? If so, you’ll be excited to hear about ChatGPT, the latest and greatest in AI language models. In this blog post, we’ll take a closer look at ChatGPT, its capabilities, and why it’s a major step forward for AI. So if you’re interested in the future of conversational AI, keep reading!\nChatGPT is a new AI language model developed by OpenAI that has the ability to understand and respond to conversational inputs in a natural and engaging way. This is a major step forward in the field of natural language processing, as it allows for more effective and engaging communication with AI systems. In this blog post, we’ll take a closer look at ChatGPT and its capabilities.\nOne of the key capabilities of ChatGPT is its ability to understand and respond to a wide range of conversational inputs. This includes both simple requests and more complex questions, making it a powerful tool for a variety of applications. ChatGPT has also been trained on a massive amount of data, allowing it to have a deep understanding of natural language and the ability to generate human-like responses.\nHow is ChatGPT related to GPT3? ChatGPT and GPT3 are related in that ChatGPT is a variant of GPT3 that has been specifically designed for conversational AI applications. GPT3, also known as Generative Pretrained Transformer 3, is a large language model trained by OpenAI. It is capable of generating human-like text and has been used for a wide range of natural language processing tasks, including language translation, summarization, and question answering.\nChatGPT is based on GPT3 and shares many of its capabilities, including its ability to generate human-like text. However, ChatGPT has been trained on a large amount of conversational data, allowing it to understand and respond to conversational inputs in a natural and engaging way. This makes it a powerful tool for conversational AI applications, such as virtual assistants and chatbots.\nIn summary, ChatGPT and GPT3 are related in that ChatGPT is a specialized variant of GPT3 that has been designed for conversational AI applications. While both models share many similar capabilities, ChatGPT has been specifically trained and optimized for conversational AI tasks.\nWhat happens when ChatGPT4 will be published in the next few months? While ChatGPT is an impressive development in AI, it is still only a teaser for what is to come with GPT4. GPT4 is the next generation of the GPT language model, and is expected to be even more powerful and capable than ChatGPT. With GPT4, we can expect even more advanced natural language processing capabilities, as well as the ability to handle a wider range of tasks and applications.\nOverall, ChatGPT is a major step forward for AI and natural language processing, but it is only a glimpse of what is to come with GPT4. As we continue to advance in the field of AI, we can expect even more impressive developments and capabilities in the near future.\nHow does the collection of data and reward model in ChatGPT work? The collection of data and reward model in ChatGPT are two key components of the model’s training process. In order to generate human-like text and engage in natural conversations, ChatGPT must be trained on large amounts of data and be able to learn from the feedback it receives.\nTo collect data for ChatGPT, the model is exposed to a wide range of conversational data, including transcripts of real-life conversations, dialogue from books and movies, and other sources of conversational text. This data is used to train the model and help it understand the structure and patterns of natural language.\nThe reward model in ChatGPT is used to evaluate the model’s performance and provide feedback on its responses. This is done through a process known as reinforcement learning, in which the model is rewarded for generating responses that are relevant, appropriate, and human-like, and is penalized for generating responses that are irrelevant or nonsensical. This feedback helps the model to learn and improve its performance over time.\nIn summary, the collection of data and reward model are key components of ChatGPT’s training process. The model is trained on large amounts of conversational data, and uses reinforcement learning to evaluate its performance and improve its responses.\nWhy are policies important for ChatGPT? Policies are important for ChatGPT because they help to ensure that the model behaves in an appropriate and ethical manner. In the context of conversational AI, policies are sets of rules and guidelines that dictate how the model should respond to different inputs and situations.\nPolicies can help to prevent ChatGPT from generating inappropriate or offensive responses, and can ensure that the model behaves in a way that aligns with the values and standards of the organization or individuals using it. For example, a policy might dictate that ChatGPT should not generate responses that are sexist, racist, or otherwise discriminatory.\nPolicies can also help to ensure that ChatGPT is used in a responsible and ethical manner. For example, a policy might dictate that ChatGPT should not be used for malicious purposes, such as spreading misinformation or harassing individuals.\nIn summary, policies are important for ChatGPT because they help to ensure that the model behaves in an appropriate and ethical manner. By defining rules and guidelines for the model’s behavior, policies can help to prevent inappropriate or offensive responses, and can ensure that ChatGPT is used in a responsible and ethical way.\nWhat are the pitfalls of ChatGPT? The pitfalls of ChatGPT include the potential for the model to generate inappropriate or offensive responses, the risk of bias and discrimination, and the potential for the model to be used for malicious purposes.\nOne of the main pitfalls of ChatGPT is the potential for the model to generate inappropriate or offensive responses. Because ChatGPT is trained on large amounts of data, it is possible that the model may be exposed to offensive or inappropriate language. If this language is included in the model’s training data, ChatGPT may generate responses that are offensive or inappropriate, even if it is not intended to do so.\nAnother potential pitfall of ChatGPT is the risk of bias and discrimination. Because the model is trained on data from the real world, it may inherit the biases and prejudices that are present in this data. For example, if the model is trained on data that is predominantly from a certain demographic group, it may generate responses that are biased towards or discriminatory towards other groups.\nFinally, another pitfall of ChatGPT is the potential for the model to be used for malicious purposes. Because ChatGPT is capable of generating human-like text, it could be used to spread misinformation or to harass or deceive individuals. This could have harmful consequences, and it is important to ensure that ChatGPT is used in an ethical and responsible manner.\nIn summary, the pitfalls of ChatGPT include the potential for the model to generate inappropriate or offensive responses, the risk of bias and discrimination, and the potential for the model to be used for malicious purposes. It is important to carefully consider these potential pitfalls and to develop policies and guidelines to prevent and mitigate them.\nI heard rumors, is ChatGPT producing wrong answers? It is possible that ChatGPT may sometimes produce results that are wrong but sound right. As a large language model, ChatGPT is capable of generating human-like text and engaging in natural conversations. However, because it is trained on data from the real world, it may inherit the biases, prejudices, and errors that are present in this data.\nFor example, if ChatGPT is trained on data that contains misinformation or false information, it may generate responses that are incorrect but sound convincing. Similarly, if the model is trained on data that is biased or discriminatory, it may generate responses that are unfair or offensive, but that sound reasonable or logical.\nTherefore, it is important to carefully monitor and evaluate ChatGPT’s responses, and to provide the model with high-quality, accurate data to train on. This can help to prevent the model from generating wrong answers that sound right, and can help to ensure that ChatGPT is used in an ethical and responsible manner.\nHow is ChatGPT related to ELIZA effect and AGI? ChatGPT is related to the ELIZA effect in that both involve the use of artificial intelligence to simulate natural language conversation. The ELIZA effect is a phenomenon in which individuals may attribute human-like qualities to a conversational AI system, even if the system is not capable of genuine intelligence or understanding. ChatGPT is a large language model that has been trained on a wide range of conversational data, allowing it to generate human-like text and engage in natural language conversations. However, like all AI systems, ChatGPT is not capable of true intelligence or understanding, and its responses are based on the data it has been trained on and the algorithms that govern its behavior. Despite this, individuals who interact with ChatGPT may be susceptible to the ELIZA effect, and may attribute human-like qualities to the model.\nChatGPT is also related to artificial general intelligence (AGI), which is a term used to describe the hypothetical ability of a machine to understand or learn any intellectual task that a human being can. While ChatGPT is a powerful and capable language model, it is not capable of AGI, and is not capable of understanding or learning any intellectual task that a human being can. ChatGPT is a specialized AI system that has been designed for a specific purpose — natural language processing — and is not capable of the general intelligence that is characteristic of AGI.\nIn summary, ChatGPT is related to the ELIZA effect in that both involve the use of AI to simulate natural language conversation, and individuals who interact with ChatGPT may be susceptible to the ELIZA effect. ChatGPT is also related to AGI in that it is a powerful and capable language model, but it is not capable of the general intelligence that is characteristic of AGI.\nSummary ChatGPT is a large language model that has been specifically designed for conversational AI applications. It has been trained on a wide range of conversational data, allowing it to understand and respond to a wide range of inputs in a natural and engaging way. Prompts are used to provide ChatGPT with a starting point for generating text, and the model is evaluated and improved through a process known as reinforcement learning.\nHowever, ChatGPT is not perfect, and may sometimes generate responses that are incorrect or inappropriate. The potential for ChatGPT to produce wrong answers is one of the pitfalls of the model, and is something that should be carefully considered when using the model for conversational AI applications. Additionally, the use of ChatGPT may be subject to the ELIZA effect, in which individuals may attribute human-like qualities to the model, even if it is not capable of genuine intelligence or understanding.\nOverall, ChatGPT is a major step forward for AI and is a powerful tool for conversational AI applications. However, it is important to carefully monitor and evaluate the model’s performance, and to provide it with high-quality training data. It is also important to develop policies and guidelines to ensure that the model is used in an ethical and responsible manner.\nFurther Links Introducing ChatGPT by Cassie Kozyrkov\nhttps://medium.com/@kozyrkov/introducing-chatgpt-aa824ad89623\nThe Batch by DeepLearningAI — Andrew Ng on LLM\nhttps://www.deeplearning.ai/the-batch/issue-174/\nAI Snake Oil on why ChatGPT is a bullshit generator\nhttps://aisnakeoil.substack.com/p/chatgpt-is-a-bullshit-generator-but\n","permalink":"https://patrickpt.github.io/posts/chatgpt-on-chatgpt/","summary":"ChatGPT: Optimizing Language Models for Dialogue\nWhat to do if you have 15Min time to spare? Feed ChatGPT with prompts to write an introductory article about ChatGPT. And I promise, this is the only part which is not based on a Large Language Model. Everything else was written by ChatGPT. For better readability I replaced the prompts with simple headers.\nWhat is ChatGPT? Are you tired of boring, robotic chatbots that can’t hold a conversation or understand your needs?","title":"An introduction to ChatGPT written by ChatGPT"},{"content":"Welcome to my blog.\nWhy not Medium? It is 2023 and there are plenty of easy ways to create content about ML, Data Science and AI on the internet. In fact with the accessability of platforms like Medium it is super easy.\nIsn\u0026rsquo;t it actually dumb to create your own blog instead of using these possibilities?\nMaybe, but my purpose is not to attract as many readers as possible but to learn something and make my learnings accessable for others.\nWell, couldn\u0026rsquo;t you have done this also on Medium?\nI tried, but starting to create content i saw some pitfalls with Medium:\nThe writing interface is straightforward and easy to use but it is actually too simple and gives almost no flexibility. Medium attracts a lot of good writers but also a lot of people just producing content with low quality. If you don\u0026rsquo;t optimize your articles you won\u0026rsquo;t attract any readers. So for my purpose there is no difference whether i use a private blog or Medium. Medium does not support Math Formulas! I could not believe it but there was no decent possibility to include math formulas with Latex or somehow else. An absolute No Go in my eyes Ok i get it, Medium is not for you but a blog is a lot of maintenance and effort. How do you find time for this?\nLuckily it is actually quite easy to create your own static site with Github Pages and Hugo. Also it is a good chance to learn somehting new and make yourself familiar with web design again. Ok, i am curious. How did you do it?\nHow did you create your blog? Which tools are you using for your blog? As written, i use Github Pages and the open-source static site generator Hugo which is written in Go. (I chose Hugo without having done a lot of research. There are other generators like e.g. Jekyll but Hugo was open-source, easy to use, blazing fast and free so no need to look further).\nAnd how did you do actually do it? Install Hugo\nbrew install hugo If you have a different system than MacOS check the official installation guide.\nCreate a new site in Hugo\nWhen you decide on a name, think that the name is also the folder and the name of the Repo. To work with Github Pages it needs to have the same name as your git user followed by .github.io\nhugo new site \u0026lt;user\u0026gt;.github.io -f yml I decided to use PaperMod theme and it recommends to use .yml Config instead of .toml - and i am fine with that because i like yaml files.\nInstall your favorite Hugo Theme\nThe project is created but if you try to run it, it will just be an empty page. A style is needed to make it fully functional.\nYou could create one from scratch but Hugo has a bunch of themes already prepared and ready to use! You can go to https://themes.gohugo.io/ and choose a theme you like. I like PaperMod\ngit init git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod Adjust your config.yml with theme: PaperMod\nbaseURL: http://\u0026lt;user\u0026gt;.github.io/ languageCode: en-us title: My New Hugo Site theme: PaperMod Create Content\nImportant is your content folder. The folder tree in this folder will reflect your site folder tree. Either you create folders and markdown files in those folders manually or you use\nhugo new e.g.\nhugo new /content/posts/first-post/first-post.md I would recommend to create a folder per post to store your pictures in the same folder as your post they relate to\n--- heading: \u0026quot;Welcome to my blog\u0026quot; subheading: \u0026quot;This is my first-post\u0026quot; --- Look at your new site\nWith\nhugo you create the html out of your content in your public folder. Please keep in mind that for Github Pages you can only choose docs as your root directory for your index.html. Therefore you need to add following config to your config.yml\npublishDir: docs With\nhugo server -D you can see the site on localhost with port 1313. -D is used to include drafts.\nPush to github\nNow you can push your site to github\ngit add . git commit -m \u0026quot;initial commit\u0026quot; git push origin main Configure Github Pages In your repo settings under Pages the root folder needs to be adjusted and your site will hopefully be deployed soon.\nWith this short introduction you should be able to set up your own blog really fast and in worst case troubleshoot your way through. Enjoy!\nI am happy with my new blog and will further play around with it. If you like my content connect via LinkedIN.\nReferences [1] Github Pages (https://pages.github.com)\n[2] Hugo (https://gohugo.io)\n[3] PaperMod (https://github.com/adityatelange/hugo-PaperMod)\n[4] Markdownguide (https://www.markdownguide.org/basic-syntax/)\n[5] Image clickable (https://discourse.gohugo.io/t/how-can-i-make-images-clickable-so-i-can-zoom-them-to-full-screen/34279)\nFurther Links [6] Folder Structure (https://jpdroege.com/blog/hugo-file-organization/)\n[7] Markdown with VS Code (https://code.visualstudio.com/docs/languages/markdown)\n[8] Trouble with Image paths (https://github.com/adityatelange/hugo-PaperMod/discussions/690)\n[9] Work in Codespaces (https://shotor.com/blog/build-a-hugo-static-site-in-your-browser-using-github-codespaces/)\n[10] Katex for PaperMod (https://adityatelange.github.io/hugo-PaperMod/posts/math-typesetting/)\n","permalink":"https://patrickpt.github.io/posts/how-to-blog/","summary":"Welcome to my blog.\nWhy not Medium? It is 2023 and there are plenty of easy ways to create content about ML, Data Science and AI on the internet. In fact with the accessability of platforms like Medium it is super easy.\nIsn\u0026rsquo;t it actually dumb to create your own blog instead of using these possibilities?\nMaybe, but my purpose is not to attract as many readers as possible but to learn something and make my learnings accessable for others.","title":"Why and how do you create your own AI blog?"},{"content":"Welcomy to my blog. I am Patrick.\nI\u0026rsquo;m living in Germany, am a proud father of two, work as a Data Scientist and love to dig into AI, Data Science and ML.\nOn this blog i am documenting my learning notes, best practices and how-to\u0026rsquo;s.\nMy blog contains my personal opinions and as i am human also errors so i am happy to receive your change requests via Github.\nAlso i am happy to connect on LinkedIN.\n","permalink":"https://patrickpt.github.io/about/","summary":"Welcomy to my blog. I am Patrick.\nI\u0026rsquo;m living in Germany, am a proud father of two, work as a Data Scientist and love to dig into AI, Data Science and ML.\nOn this blog i am documenting my learning notes, best practices and how-to\u0026rsquo;s.\nMy blog contains my personal opinions and as i am human also errors so i am happy to receive your change requests via Github.\nAlso i am happy to connect on LinkedIN.","title":"About"},{"content":"This is a list of links to stuff i found interesting recently. It will be updated regulary(whatever that means).\nIt could be a link to a paper, a nice repo or a news article. This selection is highly subjective, reflects my interests and depends on my reading habit, time, people i follow and recommender algorithms from the platforms i visit. It is not complete and is not scientific.\nI am not responsible for the linked content\n18.01.23 - 24 embarassing hours for AI [Blog]\n16.01.23 - Why do tree-based models still outperform deep learning on tabular data? [Paper]\n16.01.23 - Transformer Inference Optimization [Blog]\n15.01.23 - GPTZero [Website]\n11.01.23 - Open Source ChatGPT [Repo]\n05.01.23 - Best Papers in 2022 [Repo]\n","permalink":"https://patrickpt.github.io/recent/","summary":"This is a list of links to stuff i found interesting recently. It will be updated regulary(whatever that means).\nIt could be a link to a paper, a nice repo or a news article. This selection is highly subjective, reflects my interests and depends on my reading habit, time, people i follow and recommender algorithms from the platforms i visit. It is not complete and is not scientific.\nI am not responsible for the linked content","title":"Recent stuff i found interesting"}]