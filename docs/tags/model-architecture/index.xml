<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Model Architecture on Notes on AI</title>
    <link>https://patrickpt.github.io/tags/model-architecture/</link>
    <description>Recent content in Model Architecture on Notes on AI</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 01 Nov 2023 18:30:57 +0000</lastBuildDate><atom:link href="https://patrickpt.github.io/tags/model-architecture/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Parameter Efficient Finetuning</title>
      <link>https://patrickpt.github.io/posts/peft/</link>
      <pubDate>Wed, 01 Nov 2023 18:30:57 +0000</pubDate>
      
      <guid>https://patrickpt.github.io/posts/peft/</guid>
      <description>TL;DR Parameter Efficient Fine-Tuning is a technique that aims to reduce computational and storage resources during the fine-tuning of Large Language Models.
Why should i care? Fine-tuning is a common technique used to enhance the performance of large language models. Essentially, fine-tuning involves training a pre-trained model on a new, similar task. It has become a crucial step in model optimization. However, when these models consist of billions of parameters, fine-tuning becomes computational and storage heavy, leading to the development of Parameter Efficient Fine-Tuning methods.</description>
    </item>
    
    <item>
      <title>What is Retrieval Augmented Generation?</title>
      <link>https://patrickpt.github.io/posts/rag_intro/</link>
      <pubDate>Fri, 29 Sep 2023 18:30:57 +0000</pubDate>
      
      <guid>https://patrickpt.github.io/posts/rag_intro/</guid>
      <description>TL;DR This blogpost tries to explain Retrieval Augmented Generation. Retrieval Augmented Generation is an Architecture used for NLP tasks which can be used to productionize LLM models for enterprise architecture easily.
Why should i care? Intuitive would be to train a Large Language Model with domain specific data, in other words, to fine-tune the model-weights with custom data.
picture from Neo4J
But fine-tuning large language models (LLMs) is a complex and resource-intensive process due to several key factors:</description>
    </item>
    
    <item>
      <title>Generalized Models vs Specialized Models</title>
      <link>https://patrickpt.github.io/posts/generalvsspecializedmodels/</link>
      <pubDate>Tue, 05 Sep 2023 11:50:57 +0000</pubDate>
      
      <guid>https://patrickpt.github.io/posts/generalvsspecializedmodels/</guid>
      <description>TL;DR This blogpost focusses on ML Design and Architecture and tries to give some intuition and hints for deciding between one generalized and multiple specialized models for the same business requriement and dataset.
Consider it a nudge to dive deeper into the topic
Why should i care? Transparency in machine learning is crucial for business stakeholders because it fosters trust and informed decision-making. Business Stakeholders need to understand not only the potential benefits but also the limitations and risks associated with machine learning models.</description>
    </item>
    
  </channel>
</rss>
